{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Japan Economic Dashboard\n",
    "\n",
    "Retrieve data on macroeconomic conditions in Japan and save as csv and txt files to be read by a .tex dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:17:16.173801Z",
     "start_time": "2018-08-14T23:17:15.993690Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'quandl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8cc2276fb9cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mquandl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m   \u001b[1;31m## File with API key\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mquandl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mApiConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'quandl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import requests\n",
    "import quandl\n",
    "import config   ## File with API key\n",
    "quandl.ApiConfig.api_key = config.key\n",
    "\n",
    "def write_txt(filename, filetext):\n",
    "# Write label to txt file\n",
    "    with open(filename, 'w') as text_file:\n",
    "        text_file.write(filetext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real GDP growth \n",
    "Source: Cabinet Office \n",
    "http://www.esri.cao.go.jp/en/sna/sokuhou/sokuhou_top.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:15:23.203427Z",
     "start_time": "2018-08-14T23:15:22.824Z"
    }
   },
   "outputs": [],
   "source": [
    "# To get the latest data, need to find the correct link on the cabinet office page\n",
    "r = requests.get('http://www.esri.cao.go.jp/en/sna/sokuhou/sokuhou_top.html')\n",
    "sub = r.content[r.text.find('Time series table') - 49:r.text.find('Time series table') - 2]\n",
    "base = 'http://www.esri.cao.go.jp/en/sna'\n",
    "base2 = 'http://www.esri.cao.go.jp/jp/sna'\n",
    "r2 = requests.get(f\"{base}{sub.decode().replace('./', '/').replace('./', '/')}\")\n",
    "rloc = r2.text.find('Real, Seasonally Adjusted Series (Quarter-to-Quarter, Annualized)')\n",
    "sub2 = r2.content[rloc - 108:rloc - 18]\n",
    "url = f'{base2}{sub2.decode()}'\n",
    "url2 = url.replace('nritu','nkiyo')  # URL used for GDP growth by component\n",
    "url3 = url.replace('nritu-j', 'gaku-m')\n",
    "url4 = url.replace('nritu', 'gaku')\n",
    "url5 = url.replace('nritu', 'kgaku')\n",
    "df = pd.read_csv(url2, header=5, encoding='iso-8859-1').loc[49:]\n",
    "gdpkeep = {\n",
    "    'Unnamed: 0': 'date',\n",
    "    'GDP(Expenditure Approach)': 'gdp',\n",
    "    'PrivateConsumption': 'cons',\n",
    "    'PrivateResidentialInvestment': 'inv1',\n",
    "    'Private Non-Resi.Investment': 'inv2',\n",
    "    'Changein PrivateInventories': 'inv3',\n",
    "    'GovernmentConsumption': 'gov1',\n",
    "    'PublicInvestment': 'gov2',\n",
    "    'Changein PublicInventories': 'gov3',\n",
    "    'Goods & Services': 'nx'\n",
    "}\n",
    "df = df[list(gdpkeep.keys())].dropna()\n",
    "df.columns = df.columns.to_series().map(gdpkeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:15:23.203427Z",
     "start_time": "2018-08-14T23:15:22.829Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adjust the date column to make each value a consistent format\n",
    "dts = df['date'].str.split('-').str[0].str.split('/ ')\n",
    "for dt in dts:\n",
    "    if len(dt) == 1:\n",
    "        dt.append(dt[0])\n",
    "        dt[0] = None\n",
    "df['year'] = dts.str[0].fillna(method='ffill')\n",
    "df['month'] = dts.str[1].str.zfill(2)\n",
    "df['date2'] = df['year'].str.cat(df['month'], sep='-')\n",
    "df['date'] = pd.to_datetime(df['date2'], format='%Y-%m')\n",
    "\n",
    "# Sum up various types of investment and government spending\n",
    "df['inv'] = df['inv1'] + df['inv2'] + df['inv3']\n",
    "df['gov'] = df['gov1'] + df['gov2'] + df['gov3']\n",
    "df = df.set_index('date')[['gdp', 'cons', 'inv', 'gov', 'nx']]\n",
    "df.to_csv('data/gdp.csv', header=True)  # csv file created\n",
    "\n",
    "# Declare variables for chart label\n",
    "q = df.index[-1].quarter\n",
    "y = df.index[-1].strftime('%Y')\n",
    "Y = pd.read_csv(url4, header=5, encoding='iso-8859-1').iloc[49:, 1:2].dropna().iloc[-1].values[0]\n",
    "ch = df['gdp'][-1]\n",
    "text = '{} Q{}: Real GDP: {}billion Yen; Growth: {}\\%'.format(y, q, Y, ch)\n",
    "# Write label to txt file\n",
    "write_txt('data/gdp.txt', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labor markets (participation and unemployment rates)\n",
    "Source: Statistics Bureau \n",
    "http://www.stat.go.jp/data/roudou/longtime/zuhyou/lt01-a10.xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:15:23.207930Z",
     "start_time": "2018-08-14T23:15:22.834Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unemployment and participation\n",
    "\n",
    "# Unemployment and participation\n",
    "unemp_url = 'http://www.stat.go.jp/data/roudou/longtime/zuhyou/lt01-a10.xls'\n",
    "r = requests.get(unemp_url)\n",
    "with open('unemp.xls', 'wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "df = pd.read_excel('unemp.xls', skiprows=5, skip_footer=3).drop([1, 3])\n",
    "col1 = df.loc[0].fillna(method='ffill')\n",
    "col2 = df.loc[2]\n",
    "col = col1 + '-' + col2\n",
    "col[0] = 'year'\n",
    "col[1] = 'mon'\n",
    "col[2] = 'monname'\n",
    "col[3] = 'DEL'\n",
    "df = df.drop([0,2])\n",
    "df.columns = col.values\n",
    "df = df.drop('DEL', 1)\n",
    "df['month'] = df['mon'].str[:-1].str.zfill(2)\n",
    "df['year'] = df['year'].apply(pd.to_numeric, errors='coerce').shift(-1).fillna(method='ffill').astype(int)\n",
    "df['date2'] = df['year'].astype(str).str.cat(df['month'], sep='-')\n",
    "df['date'] = pd.to_datetime(df['date2'], format='%Y-%m')\n",
    "df = df.set_index('date').dropna()\n",
    "df['pop'] = df['Labour force-Both sexes'] + df['Not in labour force-Both sexes']\n",
    "df['partc'] = df['Labour force-Both sexes'] / df['pop'] * 100\n",
    "df['pop-m'] = df['Labour force-Male'] + df['Not in labour force-Male']\n",
    "df['partc-m'] = df['Labour force-Male'] / df['pop-m'] * 100\n",
    "df['pop-w'] = df['Labour force-Female'] + df['Not in labour force-Female']\n",
    "df['partc-w'] = df['Labour force-Female'] / df['pop-w'] * 100\n",
    "unemplt = df['Unemployment rate  (percent)-Both sexes'][-1]\n",
    "df['unemp'] = df['Unemployment rate  (percent)-Both sexes']\n",
    "d1 = df.index[-1].strftime('%b %Y')\n",
    "df = df[['partc', 'partc-m', 'partc-w', 'unemp']][636:]\n",
    "\n",
    "# Write to file\n",
    "df.to_csv('data/labor.csv', header=True)  # csv file created\n",
    "text = 'Unemployment rate, both sexes: {}: {}\\%'.format(d1, unemplt)\n",
    "# Write label to txt file\n",
    "write_txt('data/labor.txt', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Household consumption expenditure, annual growth rate\n",
    "Source: Cabinet Office http://www.esri.cao.go.jp/en/sna/sokuhou/sokuhou_top.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:15:23.207930Z",
     "start_time": "2018-08-14T23:15:22.837Z"
    }
   },
   "outputs": [],
   "source": [
    "# Household consumption expenditures \n",
    "df = pd.read_csv(url5, header=5, thousands=',', \n",
    "                 encoding='iso-8859-1').iloc[49:, [0,5,6,7,8]].dropna().set_index('Unnamed: 0')\n",
    "df['tot'] = df.sum(axis=1)\n",
    "\n",
    "series = {'DurableGoods': 'durable',\n",
    "          'Semi-DurableGoods': 'semidur',\n",
    "          'Non-DurableGoods': 'nondur',\n",
    "          'Services': 'services',\n",
    "          'tot': 'total'}\n",
    "\n",
    "df.columns = series.values()\n",
    "# Convert to share of total change\n",
    "for k, v in series.items():\n",
    "    df[v+'_ch'] = ((df[v] - df[v].shift(1))/df['total'].shift(1) * 400).round(2)\n",
    "\n",
    "df = df.dropna()    \n",
    "df['quarter'] = df.index.str.split('-').str[0].str.split('/ ').str[-1]\n",
    "df['year'] = [x for x in df.index.str.split('/ ').str[0].values if len(x) == 4 for n in range(4)][:len(df)]\n",
    "df['date'] = pd.to_datetime(df['year'].str.cat(df['quarter'], sep='-'))\n",
    "\n",
    "df = df.reset_index().set_index('date').drop(['quarter', 'year', 'Unnamed: 0'],1).dropna()\n",
    "df.to_csv('data/cons.csv', header=True)  # csv file created\n",
    "\n",
    "# Declare variables for chart label\n",
    "q = df.index[-1].quarter\n",
    "y = df.index[-1].strftime('%Y')\n",
    "C = df['total'][-1]\n",
    "ch = df['total_ch'][-1]\n",
    "text = 'Total household consumption expenditure: \\\\\\ {} Q{}: {:,} billion Yen; Growth: {}\\%'.format(y, q, C, ch)\n",
    "# Write label to txt file\n",
    "write_txt('data/cons.txt', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Investment expenditure by sector\n",
    "Source: Cabinet Office http://www.esri.cao.go.jp/en/sna/sokuhou/sokuhou_top.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:15:23.207930Z",
     "start_time": "2018-08-14T23:15:22.848Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(url4, header=5, thousands=',', \n",
    "                 encoding='iso-8859-1').iloc[49:, [0,5,6,9]].dropna().set_index('Unnamed: 0')\n",
    "df['tot'] = df.sum(axis=1)\n",
    "\n",
    "series2 = {'PrivateResidentialInvestment': 'res',\n",
    "           'Private Non-Resi.Investment': 'bus', \n",
    "           'PublicInvestment': 'pub', \n",
    "           'tot': 'total'}\n",
    "\n",
    "df.columns = series2.values()\n",
    "# Convert to share of total change\n",
    "for k, v in series2.items():\n",
    "    df[v+'_ch'] = ((df[v] - df[v].shift(1))/df['total'].shift(1) * 400).round(2)\n",
    "    \n",
    "df['quarter'] = df.index.str.split('-').str[0].str.split('/ ').str[-1]\n",
    "df['year'] = [x for x in df.index.str.split('/ ').str[0].values if len(x) == 4 for n in range(4)][:len(df)]\n",
    "df['date'] = pd.to_datetime(df['year'].str.cat(df['quarter'], sep='-'))\n",
    "\n",
    "df = df.reset_index().set_index('date').drop(['quarter', 'year', 'Unnamed: 0'],1).dropna()\n",
    "df.to_csv('data/inv.csv', header=True)  # csv file created\n",
    "\n",
    "# Declare variables for chart label\n",
    "q = df.index[-1].quarter\n",
    "y = df.index[-1].strftime('%Y')\n",
    "I = df['total'][-1]\n",
    "ch = df['total_ch'][-1]\n",
    "text = 'Total investment expenditure: \\\\\\{} Q{}: {:,} billion Yen; Growth: {}\\%'.format(y, q, I, ch)\n",
    "# Write label to txt file\n",
    "write_txt('data/inv.txt', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Industrial Production Index\n",
    "Source: Ministry of Economy Trade and Industry http://www.meti.go.jp/english/statistics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:15:23.207930Z",
     "start_time": "2018-08-14T23:15:22.851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Industrial production\n",
    "url = 'http://www.meti.go.jp/english/statistics/tyo/iip/xls/b2010_gsm1e.xls'\n",
    "series = {\n",
    "    2000000000: '\\\\textbf{All manufacturing and mining}',\n",
    "    '2AC0000000': 'Fabricated metals',\n",
    "    '2AD0000000': 'Machinery',\n",
    "    '2AE0000000': 'Electrical parts \\& devices',\n",
    "    '2AF0000000': 'Electrical machinery',\n",
    "    '2AG0000000': 'Information \\& communication eq.',\n",
    "    '2AH0000000': 'Transport equipment',\n",
    "    '2AJ0000000': 'Chemicals',\n",
    "    '2AL0000000': 'Plastic products',\n",
    "    '2AO0000000': 'Foods and tobacco',\n",
    "    '2AP0000000': 'Other manufacturing',\n",
    "}\n",
    "\n",
    "df = pd.read_excel(url, skiprows=2).set_index('Item_Number').iloc[:,-60:]\n",
    "df = df[df.index.isin(series.keys())]\n",
    "df.replace({'-': None}, regex=True, inplace=True)\n",
    "dfs = pd.DataFrame()\n",
    "if len([col for col in df.columns if 'p' in str(col)]) > 0:\n",
    "    dfs['pre'] = df.iloc[:,-1]\n",
    "    dfs['lt'] = df.iloc[:,-2]\n",
    "    predate = '{} (Preliminary)'.format(pd.to_datetime(df.columns[-1][-6:], format='%Y%m').strftime('%b %Y'))\n",
    "    ltdate = '{}'.format(pd.to_datetime(df.columns[-2], format='%Y%m').strftime('%b %Y'))\n",
    "    legend = '\\legend{{\\scriptsize 5-year range, \\scriptsize 1-year average, \\scriptsize {}, \\scriptsize {}}}'.format(ltdate, predate)\n",
    "else:\n",
    "    dfs['pre'] = None\n",
    "    dfs['lt'] = df.iloc[:,-1]  \n",
    "    predate = None\n",
    "    ltdate = '{}'.format(pd.to_datetime(df.columns[-1], format='%Y%m').strftime('%b %Y'))\n",
    "    legend = '\\legend{{\\scriptsize 5-year range, \\scriptsize 1-year avg, \\scriptsize {}}}'.format(ltdate)\n",
    "dfs['avg'] = df.mean(axis=1) #.ix[:,-12:]\n",
    "dfs['min'] = df.min(axis=1)\n",
    "dfs['max'] = df.max(axis=1) - dfs['min']\n",
    "dfs['industry'] = dfs.index.to_series().map(series)\n",
    "dfs = dfs.sort_values('lt', ascending=False)\n",
    "dfs = dfs.reset_index()\n",
    "dfs = dfs.drop('Item_Number', 1).set_index('industry')\n",
    "#Write to file\n",
    "write_txt('data/ipleg.txt', legend)\n",
    "dfs.to_csv('data/ip.csv', header = True)  # csv file created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### TANKAN\n",
    "Source: Bank of Japan through Quandl http://www.boj.or.jp/en/statistics/tk/index.htm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:15:23.207930Z",
     "start_time": "2018-08-14T23:15:22.855Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tankan Business Conditions\n",
    "#series = {'BOJ/COCOAEF1000601GCQ00000AT': 'All',\n",
    "#          'BOJ/COCOAEF1000601GCQ01000AT': 'Large',\n",
    "#          'BOJ/COCOAEF1000601GCQ02000AT': 'Medium',\n",
    "#          'BOJ/COCOAEF1000601GCQ03000AT': 'Small'\n",
    "#     }\n",
    "# Retrieve from quandl\n",
    "#df = quandl.get(series.keys()).dropna()[64:]\n",
    "#df.columns = series.values()\n",
    "#df.index = pd.to_datetime(df.index)\n",
    "#d1 = '{} Q{}'.format(df.index[-1].year, df.index[-1].quarter)\n",
    "#all1 = df['All'][-1].astype(int)\n",
    "#df.index.name = 'date'\n",
    "#df.to_csv('data/tankan_bc.csv', header=True)  # csv file created\n",
    "#text = 'As of {}: All-firms: {}'.format(d1, all1)\n",
    "# Write label to txt file\n",
    "#write_txt('data/tankan_bc.txt', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Consumer price index\n",
    "Source: Statistics Bureau http://www.e-stat.go.jp/SG1/estat/CsvdlE.do?sinfid=000031431696"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:15:23.207930Z",
     "start_time": "2018-08-14T23:15:22.859Z"
    }
   },
   "outputs": [],
   "source": [
    "# CPI data from e-stat.go.jp\n",
    "#http://www.e-stat.go.jp/SG1/estat/CsvdlE.do?sinfid=000031431696\n",
    "cpi_url = 'http://www.e-stat.go.jp/SG1/estat/CsvdlE.do?sinfid=000031431696'\n",
    "cpi_comp = {\n",
    "    'All items': 'All',\n",
    "    'All items, less food (less alcoholic beverages) and energy': 'Core',\n",
    "    'Food': 'Food \\& beverage',\n",
    "    'Housing': 'Housing',\n",
    "    'Furniture & household utensils': 'Furniture \\& utensils',\n",
    "    'Clothes & footwear': 'Apparel',\n",
    "    'Medical care': 'Healthcare',\n",
    "    'Transportation & communication': 'Transportation',\n",
    "    'Education': 'Education',\n",
    "    'Culture & recreation': 'Recreation',\n",
    "    'Energy': 'Energy'\n",
    "}\n",
    "\n",
    "df = pd.read_csv(cpi_url, header=1, \n",
    "                 encoding='iso-8859-1').loc[424:].set_index('Group/Item')\n",
    "df = df[list(cpi_comp.keys())].pct_change(12).dropna()\n",
    "df['date'] = pd.to_datetime(df.index, format='%Y%m')\n",
    "df = df.reset_index().set_index('date').drop('Group/Item', 1).multiply(100).round(1)\n",
    "df.columns = df.columns.to_series().map(cpi_comp)\n",
    "\n",
    "df[['All', 'Core']].to_csv('data/cpi.csv', header=True)  # csv file created\n",
    "\n",
    "# Declare variables for chart label\n",
    "v1 = df['All'].iloc[-1]\n",
    "v2 = df['Core'].iloc[-1]\n",
    "d1 = df.index[-1].strftime('%b %Y')\n",
    "text = '{}: All-items CPI: {}\\%; Core CPI: {}\\%'.format(d1, v1, v2)\n",
    "# Write label to txt file\n",
    "write_txt('data/cpi.txt', text)\n",
    "\n",
    "# Write legend months to txt file\n",
    "with open('data/cpi_mo1.txt', 'w') as text_file:\n",
    "    text_file.write(df.index[-2].strftime('%b %Y'))\n",
    "with open('data/cpi_mo2.txt', 'w') as text_file:\n",
    "    text_file.write(df.index[-1].strftime('%b %Y'))  \n",
    "\n",
    "d = {s: df[s][-120:].mean() for s in df.keys()} # Five year average\n",
    "    \n",
    "df = df.drop('Core', 1).tail(2).transpose().round(decimals=1)\n",
    "df.columns = ['one', 'two']\n",
    "df.index.name = 'Item'\n",
    "df['ten'] = df.index.to_series().map(d).round(1)\n",
    "df = df.set_index(df.reset_index()['Item'].replace('All', '\\\\textbf{All-items}'))\n",
    "df = df.sort_values(by='two', axis=0, ascending=False)\n",
    "df.to_csv('data/cpi_comp.csv', header = True)  # csv file created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Nikkei 225\n",
    "Source: Nikkei http://indexes.nikkei.co.jp/en/nkave/historical/nikkei_stock_average_daily_en.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:15:23.207930Z",
     "start_time": "2018-08-14T23:15:22.863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Nikkei 225\n",
    "df = pd.DataFrame()\n",
    "nikurl = 'http://indexes.nikkei.co.jp/en/nkave/historical/nikkei_stock_average_daily_en.csv'\n",
    "df['close'] = pd.read_csv(nikurl, skipfooter=1, parse_dates=['Date of Data'], engine='python'\n",
    "                         , encoding='iso-8859-1').set_index('Date of Data')['Close']\n",
    "df['vol'] = df['close'].pct_change() * 100\n",
    "df.index.name = 'date'\n",
    "d1 = df.index[-1].strftime('%b %#d, %Y')\n",
    "n1 = '{0:,.1f}'.format(df['close'][-1])\n",
    "\n",
    "# LaTeX arrows\n",
    "upar = ' \\color{green!80!blue}$\\\\blacktriangle$\\\\normalcolor'\n",
    "dnar = ' \\color{red!80!orange}$\\\\blacktriangledown$\\\\normalcolor'\n",
    "\n",
    "d = {}\n",
    "d['onemo'] = df['close'].dropna().pct_change(periods=21).multiply(100).round(1)[-1]\n",
    "d['oneyr'] = df['close'].dropna().pct_change(periods=252).multiply(100).round(1)[-1]\n",
    "for s in ['onemo', 'oneyr']:  # Loop for yearly and monthly changes\n",
    "    if d[s] > 0.005:\n",
    "        d[s+'_ar'] = upar # Green up arrow if positive\n",
    "    elif d[s] < -0.005:\n",
    "        d[s+'_ar'] = dnar # Red down arrow if negative\n",
    "    else:\n",
    "        d[s+'_ar'] = '' # For cases with no change\n",
    "        \n",
    "df.dropna().to_csv('data/nikkei.csv', header=True)  # csv file created\n",
    "text = 'One-month change:{} {}\\%; \\\\\\ One-year change:{} {}\\%'.format(\n",
    "            d['onemo_ar'], d['onemo'], d['oneyr_ar'], d['oneyr'])\n",
    "text2 = 'Latest value: {}: {}'.format(d1, n1)\n",
    "# Write label to txt file\n",
    "write_txt('data/nikkei.txt', text)\n",
    "write_txt('data/nikkei2.txt', text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Japanese Government Bonds\n",
    "Source: Ministry of Finance http://www.mof.go.jp/english/jgbs/reference/interest_rate/jgbcme.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:15:23.213444Z",
     "start_time": "2018-08-14T23:15:22.868Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'http://www.mof.go.jp/english/jgbs/reference/interest_rate/jgbcme.csv'\n",
    "url1 = 'http://www.mof.go.jp/english/jgbs/reference/interest_rate/historical/jgbcme_all.csv'\n",
    "\n",
    "df = pd.read_csv(url, skiprows=1, parse_dates=['Date']).set_index('Date')\n",
    "df1 = pd.read_csv(url1, skiprows=1, parse_dates=['Date']).iloc[9700:].set_index('Date')\n",
    "\n",
    "df = df1.append(df)[['1Y', '2Y', '5Y', '10Y', '20Y', '30Y', '40Y']].dropna()\n",
    "\n",
    "prev1 = df.iloc[-246]\n",
    "prev1dt = '{}'.format(prev1.name.strftime('%b %#d, %Y'))\n",
    "prev5 = df.iloc[-1227]\n",
    "prev5dt = '{}'.format(prev5.name.strftime('%b %#d, %Y'))\n",
    "curr = df.iloc[-1]\n",
    "currdt = '{}'.format(curr.name.strftime('%b %#d, %Y'))\n",
    "head = [curr, prev1, prev5]\n",
    "df1 = pd.concat(head, 1)\n",
    "df1.columns = ['curr', 'prev1', 'prev5']\n",
    "df1['number'] = ['1', '2', '3', '4', '5', '6', '7']\n",
    "df1['alignment'] = 270\n",
    "df1.to_csv('data/jgb.csv', header=True)  # csv file created\n",
    "\n",
    "# Write label to txt file\n",
    "write_txt('data/jgb_prev1.txt', prev1dt)\n",
    "write_txt('data/jgb_prev5.txt', prev5dt)\n",
    "write_txt('data/jgb_curr.txt', currdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current Account Balance to GDP\n",
    "Source: Ministry of Finance http://www.mof.go.jp/international_policy/reference/balance_of_payments/bp_trend/bpnet/sbp/s-a/6s-a-1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:15:23.213444Z",
     "start_time": "2018-08-14T23:15:22.873Z"
    }
   },
   "outputs": [],
   "source": [
    "# Current account from Ministry of Finance balance of payments data\n",
    "url = 'http://www.mof.go.jp/international_policy/reference/balance_of_payments/bp_trend/bpnet/sbp/s-a/6s-a-1.csv'\n",
    "columns = ['year' ,'quarter', 'cab', 'gs', 'goods', 'ex', 'im', 'serv', 'income', 'transfers']\n",
    "series = ['cab', 'goods', 'serv', 'income', 'transfers']\n",
    "df = pd.read_csv(url, skiprows=28, thousands=',', encoding='iso-8859-1').iloc[:,2:].drop('Unnamed: 4',1)\n",
    "df.columns = columns\n",
    "df['quarter'] = df['quarter'].str[0]\n",
    "df['year'] = df['year'].fillna(method='ffill').astype(int)\n",
    "df['date'] = pd.to_datetime(df['year'].map(str) + 'Q' + df['quarter'])\n",
    "df = df.set_index('date')\n",
    "df = df.iloc[40:,:]\n",
    "\n",
    "# Nominal GDP from cabinet office\n",
    "ngdp = pd.read_csv(url3, header=5, thousands=',').iloc[49:, 0:2].dropna()\n",
    "dts = ngdp['Unnamed: 0'].str.split('-').str[0].str.split('/ ')\n",
    "for dt in dts:\n",
    "    if len(dt) == 1:\n",
    "        dt.append(dt[0])\n",
    "        dt[0] = None\n",
    "ngdp['year'] = dts.str[0].fillna(method='ffill')\n",
    "ngdp['month'] = dts.str[1].str.zfill(2)\n",
    "ngdp['date2'] = ngdp['year'].str.cat(ngdp['month'], sep='-')\n",
    "ngdp['date'] = pd.to_datetime(ngdp['date2'], format='%Y-%m')\n",
    "ngdp = ngdp.set_index('date')['GDP(Expenditure Approach)']\n",
    "ngdp.name = 'gdp'\n",
    "\n",
    "df = df.join(ngdp).dropna()\n",
    "df = df[series].div(df['gdp'].multiply(.025), axis=0).round(2).join(df[['ex', 'im']].div(10))\n",
    "df.to_csv('data/external.csv', header=True)  # csv file created\n",
    "\n",
    "# Declare variables for chart label\n",
    "q = df.index[-1].quarter\n",
    "y = df.index[-1].strftime('%Y')\n",
    "lt = df['cab'][-1]\n",
    "exim = 'Exports: {:,}; Imports {:,}'.format(df['ex'][-1], df['im'][-1])\n",
    "text = '{} Q{}: Current Account Balance: {}\\% of GDP'.format(y, q, lt)\n",
    "text2 = '{} Q{}: {} (goods only, billion Yen)'.format(y, q, exim)\n",
    "# Write label to txt file\n",
    "write_txt('data/cab.txt', text)\n",
    "write_txt('data/tb.txt', text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foreign Exchange\n",
    "Source: FRED and Quandl https://www.quandl.com/data/CURRFX/USDJPY https://www.boj.or.jp/en/statistics/market/forex/jikko/index.htm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:15:23.213444Z",
     "start_time": "2018-08-14T23:15:22.876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Updated inputs to pandas datareader:\n",
    "source = 'fred' \n",
    "start = datetime.datetime(2013,1,1)\n",
    "series = {'RBJPBIS': 'REER',\n",
    "          'NBJPBIS': 'NEER'}\n",
    "series2 = {'BOE/XUDLJYD': 'Rate'}\n",
    "\n",
    "# Retrieve data as pandas dataframe named df\n",
    "df = web.DataReader(list(series.keys()), source, start)\n",
    "df.columns = series.values()\n",
    "dft = 1 / quandl.get(list(series2.keys()), start_date='2013-01-01')['BOE/XUDLJYD - Value']\n",
    "dft = dft.rename('Rate')\n",
    "df2 = df.join(dft, how='outer').fillna(method='bfill').loc['2014-01-01':]\n",
    "#df2['Rate'] = df2['Rate'].fillna(method='bfill')\n",
    "\n",
    "label = 'As of {}: {} JPY per 1 USD'.format(df2.index[-1].strftime('%b %#d, %Y'), (1 / df2['Rate'][-1]).round(2))\n",
    "for column in df2.columns:\n",
    "    df2[column] = df2[column] / df2.dropna()[column][0]\n",
    "\n",
    "df2.to_csv('data/fx.csv', header=True, index_label='Date')  # csv file created\n",
    "\n",
    "# Write label to txt file\n",
    "write_txt('data/usdjpy.txt', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run LaTeX file with chart details\n",
    "\n",
    "If .tex file runs to completion and produces a pdf file, the cell below will produce output of \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T23:15:23.213444Z",
     "start_time": "2018-08-14T23:15:22.878Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "os.system('pdflatex JPNDash.tex')\n",
    "shutil.copy('JPNDash.pdf', 'C:/Working/bdecon.github.io/Dash/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
